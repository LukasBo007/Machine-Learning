{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP for Regression**\n",
    "\n",
    "A linear regression model has the common form: $y=\\alpha + \\sum\\limits_{i=1}^{n}\\beta_i \\cdot x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(\"C:\\Code\\KI\\Moodle\\RealEstate (1).csv\")\n",
    "rawdata[\"ART\"] = pd.Categorical(rawdata.ART, ['Flat', 'Attached', 'House'])\n",
    "rawdata = rawdata.iloc[:, np.r_[6, 0:6, 7:8]]\n",
    "rawdata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = rawdata.corr()\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1.0, vmax=1.0, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "#print(rawdata.info())\n",
    "print(rawdata.isnull().sum())\n",
    "\n",
    "# Dealing with missing values\n",
    "# (1) Deleting the column with missing values\n",
    "# rawdata = rawdata.dropna(axis=1)\n",
    "\n",
    "# (2) Deleting the row with missing values\n",
    "# rawdata = rawdata.dropna(axis=0)\n",
    "\n",
    "# (3) Imputation - filling the missing values\n",
    "#rawdata['PRICE'] = rawdata['PRICE'].fillna(rawdata['PRICE'].median())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers\n",
    "# Pandas boxplot\n",
    "rawdata.boxplot(grid=False)\n",
    "#rawdata.boxplot(column=['PRICE'], grid=False)\n",
    "# Seaborn boxplot\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(data=rawdata['PRICE'])\n",
    "\n",
    "# Dealing with outliers\n",
    "# Interquartile range (IQR)\n",
    "Q1 = rawdata['PRICE'].quantile(q=0.25, interpolation='midpoint') # Q1 = np.percentile(rawdata['PRICE'], q=25, method='midpoint')\n",
    "Q3 = rawdata['PRICE'].quantile(q=0.75, interpolation='midpoint') # Q3 = np.percentile(rawdata['PRICE'], q=75, method='midpoint')\n",
    "IQR = Q3 - Q1\n",
    "print('Interquartile range: ', round(IQR, 2))\n",
    "# Upper bound\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "upper= np.array(rawdata['PRICE'] > upper_bound)\n",
    "print('Sum of upper values: ', upper.sum())\n",
    "# Lower bound\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "lower = np.array(rawdata['PRICE'] < lower_bound)\n",
    "print('Sum of lower values: ', lower.sum())\n",
    "# Setting outliers to boundaries\n",
    "rawdata.loc[rawdata['PRICE'] > upper_bound, 'PRICE'] = upper_bound\n",
    "rawdata.loc[rawdata['PRICE'] < lower_bound, 'PRICE'] = lower_bound"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.get_dummies(rawdata, columns=[\"ART\"], drop_first=True)\n",
    "rawdata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(rawdata.to_numpy(), shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X and y\n",
    "train_X, train_y = train[:, 1:], train[:, 0].reshape(-1, 1)\n",
    "test_X, test_y = test[:, 1:], test[:, 0].reshape(-1, 1)\n",
    "\n",
    "# Fit a scaler on the training set and distinguish between X and y fits for later inverse transformations\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "train_scaled_X = scaler_X.fit_transform(train_X)\n",
    "train_scaled_y = scaler_y.fit_transform(train_y)\n",
    "# Apply the same scalers with learned parameters from training set on test set\n",
    "test_scaled_X = scaler_X.transform(test_X)\n",
    "test_scaled_y = scaler_y.transform(test_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model\n",
    "### Extract X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nunits(a):\n",
    "    \"\"\"Number of units (features or outcomes)\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    a : array-like\n",
    "        A ndarray.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Number of units : int\n",
    "\n",
    "    \"\"\"\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.reshape(-1, 1)\n",
    "    return a.shape[-1]\n",
    "\n",
    "num_X = nunits(train_scaled_X)\n",
    "num_y = nunits(train_scaled_y)\n",
    "print(\"Number of features: {0} and number of outcomes: {1}\".format(num_X, num_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input = Input(shape=(num_X,))\n",
    "# Hidden layers\n",
    "hidden = Dense(units=128, activation='relu')(input)\n",
    "hidden = Dense(units=64, activation='relu')(hidden)\n",
    "hidden = Dense(units=32, activation='relu')(hidden)\n",
    "hidden = Dense(units=16, activation='relu')(hidden)\n",
    "# Output layer\n",
    "output = Dense(units=num_y, activation='linear')(hidden)\n",
    "\n",
    "# Entire model\n",
    "model = Model(inputs=input, outputs=output, name='Regression')\n",
    "\n",
    "# Summarize layers\n",
    "print(model.summary())\n",
    "\n",
    "# Plot model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of the training process\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Fit model\n",
    "model.fit(x=train_scaled_X, y=train_scaled_y, epochs=50, batch_size=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "### Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepann.metrics import rmse\n",
    "def rmse(actuals, preds):\n",
    "    \"\"\"Root mean squared error (RMSE)\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        actuals : vector-like, e.g. list, tupel, array\n",
    "            A numeric vector with actual values.\n",
    "        preds : vector-like, e.g. list, tupel, array\n",
    "            A numeric vector with predicted values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "       Root mean squared error : numpy.float\n",
    "    \"\"\"\n",
    "    actuals, preds = np.array(actuals), np.array(preds)\n",
    "    error = actuals - preds\n",
    "    mse = np.mean(error**2)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "# In-sample and out-of-sample predictions\n",
    "train_yhat = model.predict(train_scaled_X)\n",
    "test_yhat = model.predict(test_scaled_X)\n",
    "# Inverse transforming because of scaled values\n",
    "train_rescaled_yhat = scaler_y.inverse_transform(train_yhat)\n",
    "test_rescaled_yhat = scaler_y.inverse_transform(test_yhat)\n",
    "# Compute RMSE\n",
    "rmse_train = round(rmse(train_y, train_rescaled_yhat), 2)\n",
    "rmse_test = round(rmse(test_y, test_rescaled_yhat), 2)\n",
    "print(\"RMSE: Train = {0}, test = {1}\".format(rmse_train, rmse_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "# In-sample plot\n",
    "axes[0].plot(train_y, label='Actual', linestyle='solid', color='darkblue')\n",
    "axes[0].plot(train_rescaled_yhat, label='Predicted', linestyle='solid', color='darkred')\n",
    "axes[0].set_title(\"In-sample\")\n",
    "axes[0].set_ylabel('PRICE')\n",
    "axes[0].legend()\n",
    "# Out-of-sample plot\n",
    "axes[1].plot(test_y, label='Actual', linestyle='solid', color='darkgreen')\n",
    "axes[1].plot(test_rescaled_yhat, label='Predicted', linestyle='solid', color='orange')\n",
    "axes[1].set_title(\"Out-of-sample\")\n",
    "axes[1].legend()\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression analysis\n",
    "\n",
    "Preferred python packages are [NumPy](https://numpy.org/), [scikit-learn](https://scikit-learn.org/) and [statsmodels](https://www.statsmodels.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "regmodel = LinearRegression().fit(X=train_X, y=train_y)\n",
    "\n",
    "# Model parameters\n",
    "r_sq = round(regmodel.score(train_X, train_y), 2)\n",
    "print(f\"Coefficient of determination: {r_sq}\")\n",
    "print(f\"Intercept: {[round(item, 2) for item in regmodel.intercept_.reshape(-1)]}\")\n",
    "coefficients = dict(zip(rawdata.columns.to_list()[1:], [round(item, 2) for item in regmodel.coef_.reshape(-1)]))\n",
    "print(f\"Coefficients: {coefficients}\")\n",
    "\n",
    "# Predict response\n",
    "yhat = regmodel.predict(train_X)\n",
    "print(f\"RMSE: {round(rmse(train_y, yhat), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf5e281a374624e73df36f138a2d9e9531cb62603d537b8afcf2b5427de60132"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
